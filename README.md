# Pyspark

Getting started with PySpark 

## Spark  â€“ Overview

Apache Spark is a lightning fast real-time processing framework. 

Apache Spark has its own cluster manager, where it can host its application. It leverages Apache Hadoop for both storage and processing.

- It does in-memory computations to analyze data in real-time
- It does batch processing
- It supports interactive queries and iterative algorithms

## PySpark

Apache Spark is written in Scala programming language. To support Python with Spark, Apache Spark Community released a tool, PySpark. It uses a library called Py4j.

PySpark offers PySpark Shell which links the Python API to the spark core and initializes the Spark context.
